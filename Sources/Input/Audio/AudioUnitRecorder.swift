//
//  AudioUnitRecorder.swift
//  OnesecCore
//
//  Created by ç‹æ™“é›¨ Wang on 2025/12/11.
//

import AudioToolbox
import AVFoundation
import Collections
import Combine
import Foundation
import Opus

enum RecordState {
    case idle
    case recording
    case recordingTimeout
    case processing
    case stopping
}

/// åŸºäº Audio Unit çš„å½•éŸ³å™¨
/// é¿å… AVAudioEngine çš„èšåˆè®¾å¤‡é—®é¢˜
class AudioUnitRecorder: @unchecked Sendable {
    @Published var recordState: RecordState = .idle

    // Audio Unit ç»„ä»¶

    private var audioUnit: AudioUnit?
    private var avAudioConverter: AVAudioConverter?
    private var opusEncoder: OpusEncoder!
    private var oggPacketizer: OpusOggStreamPacketizer!

    // éŸ³é¢‘æ ¼å¼

    private let targetFormat = AudioStreamBasicDescription(
        mSampleRate: 16000.0,
        mFormatID: kAudioFormatLinearPCM,
        mFormatFlags: kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked,
        mBytesPerPacket: 2,
        mFramesPerPacket: 1,
        mBytesPerFrame: 2,
        mChannelsPerFrame: 1,
        mBitsPerChannel: 16,
        mReserved: 0
    )

    private var inputFormat = AudioStreamBasicDescription()
    private var inputAVFormat: AVAudioFormat?
    private let targetAVFormat: AVAudioFormat = .init(
        commonFormat: .pcmFormatInt16,
        sampleRate: 16000.0,
        channels: 1,
        interleaved: true
    )!

    // å½•éŸ³é…ç½®

    private let opusFrameSamples = 160 // 10ms @ 16kHz
    private var opusFramesPerPacket = 20 // é»˜è®¤èšåˆ 200ms

    private var audioQueue: Deque<Data> = .init()
    private var recordedAudioData = Data()
    private var cancellables = Set<AnyCancellable>()
    private var queueStartTime: Date?
    private var isRecordingStarted = false
    private var recordMode: RecordMode = .normal

    // å½•éŸ³ç»Ÿè®¡æ•°æ®

    private var totalPacketsSent = 0
    private var totalBytesSent = 0
    private var totalRawBytesSent = 0
    private var recordingStartTime: Date?
    private var recordingStopTime: Date?

    // å½•éŸ³æ—¶é•¿é™åˆ¶

    private let maxRecordingDuration: TimeInterval = 300
    private let warningBeforeTimeout: TimeInterval = 15
    private var recordingLimitTimer: Timer?

    // çº¿ç¨‹å®‰å…¨

    private let lock = NSLock()

    init() {
        setupOpusEncoderAndPacketizer()
        setupAudioEventListener()
    }

    deinit {
        cleanup()
    }

    private func setupOpusEncoderAndPacketizer() {
        let avFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: 16000.0,
            channels: 1,
            interleaved: true
        )!

        opusEncoder = OpusEncoder(
            format: avFormat,
            application: .voip,
            frameSize: AVAudioFrameCount(opusFrameSamples)
        )

        oggPacketizer = OpusOggStreamPacketizer(
            sampleRate: Int(targetFormat.mSampleRate),
            channelCount: Int(targetFormat.mChannelsPerFrame),
            opusFrameSamples: opusFrameSamples,
            framesPerPacket: opusFramesPerPacket
        )

        guard opusEncoder != nil else {
            log.error("Unexpected OpusEncoder Init")
            return
        }
    }

    private func setupAudioUnit() throws {
        lock.lock()
        defer { lock.unlock() }

        if let unit = audioUnit {
            // å°è¯•è·å–å±æ€§éªŒè¯ Audio Unit æ˜¯å¦çœŸæ­£å¯ç”¨
            var propertySize = UInt32(MemoryLayout<AudioStreamBasicDescription>.size)
            var testFormat = AudioStreamBasicDescription()
            let status = AudioUnitGetProperty(
                unit,
                kAudioUnitProperty_StreamFormat,
                kAudioUnitScope_Input,
                1,
                &testFormat,
                &propertySize
            )

            if status == noErr {
                log.debug("Audio Unit å·²åˆå§‹åŒ–ä¸”æœ‰æ•ˆ,è·³è¿‡é‡å¤åˆå§‹åŒ–")
                return
            } else {
                // Audio Unit æ— æ•ˆ,æ¸…ç©ºå¹¶é‡æ–°åˆ›å»º
                log.warning("Audio Unit æŒ‡é’ˆå­˜åœ¨ä½†å·²å¤±æ•ˆ (status: \(status)),é‡æ–°åˆå§‹åŒ–")
                audioUnit = nil
                avAudioConverter = nil
                inputAVFormat = nil
            }
        }

        // 1. è·å– HAL Output Audio Unit ç»„ä»¶æè¿°
        var componentDesc = AudioComponentDescription(
            componentType: kAudioUnitType_Output,
            componentSubType: kAudioUnitSubType_HALOutput,
            componentManufacturer: kAudioUnitManufacturer_Apple,
            componentFlags: 0,
            componentFlagsMask: 0
        )

        guard let component = AudioComponentFindNext(nil, &componentDesc) else {
            throw NSError(domain: "AudioUnit", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to find audio component"])
        }

        // 2. åˆ›å»º Audio Unit å®ä¾‹
        var audioUnitInstance: AudioUnit?
        var status = AudioComponentInstanceNew(component, &audioUnitInstance)
        guard status == noErr, let unit = audioUnitInstance else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to create audio unit: \(status)"])
        }

        audioUnit = unit

        // 3. å¯ç”¨è¾“å…¥ï¼Œç¦ç”¨è¾“å‡º
        var enableInput: UInt32 = 1
        status = AudioUnitSetProperty(
            unit,
            kAudioOutputUnitProperty_EnableIO,
            kAudioUnitScope_Input,
            1, // è¾“å…¥æ€»çº¿
            &enableInput,
            UInt32(MemoryLayout<UInt32>.size)
        )
        guard status == noErr else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to enable input: \(status)"])
        }

        var disableOutput: UInt32 = 0
        status = AudioUnitSetProperty(
            unit,
            kAudioOutputUnitProperty_EnableIO,
            kAudioUnitScope_Output,
            0, // è¾“å‡ºæ€»çº¿
            &disableOutput,
            UInt32(MemoryLayout<UInt32>.size)
        )
        guard status == noErr else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to disable output: \(status)"])
        }

        // 4. è®¾ç½®è¾“å…¥è®¾å¤‡ï¼ˆè‹¥ç”¨æˆ·è®¾å¤‡å·²å¤±æ•ˆåˆ™å›é€€åˆ°ç³»ç»Ÿé»˜è®¤ï¼‰
        let deviceManager = AudioDeviceManager.shared
        var deviceID = deviceManager.selectedDeviceID ?? 0
        status = AudioUnitSetProperty(
            unit,
            kAudioOutputUnitProperty_CurrentDevice,
            kAudioUnitScope_Global,
            0,
            &deviceID,
            UInt32(MemoryLayout<AudioDeviceID>.size)
        )

        if status != noErr {
            let systemDefaultID = deviceManager.selectedDeviceID ?? 0
            if systemDefaultID > 0, systemDefaultID != deviceID {
                log.warning("æŒ‡å®šè¾“å…¥è®¾å¤‡ä¸å¯ç”¨(\(deviceID)), å›é€€åˆ°ç³»ç»Ÿé»˜è®¤: \(systemDefaultID)")
                deviceID = systemDefaultID
                status = AudioUnitSetProperty(
                    unit,
                    kAudioOutputUnitProperty_CurrentDevice,
                    kAudioUnitScope_Global,
                    0,
                    &deviceID,
                    UInt32(MemoryLayout<AudioDeviceID>.size)
                )
            }
        }

        guard status == noErr else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to set device: \(status)"])
        }

        log.info("âœ… å·²è®¾ç½®è¾“å…¥è®¾å¤‡: \(deviceID)")

        // 5. è·å–è¾“å…¥è®¾å¤‡çš„æ ¼å¼
        var propertySize = UInt32(MemoryLayout<AudioStreamBasicDescription>.size)
        status = AudioUnitGetProperty(
            unit,
            kAudioUnitProperty_StreamFormat,
            kAudioUnitScope_Input,
            1,
            &inputFormat,
            &propertySize
        )
        guard status == noErr else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to get input format: \(status)"])
        }

        log.debug("è¾“å…¥æ ¼å¼: \(inputFormat.mSampleRate)Hz \(inputFormat.mChannelsPerFrame)å£°é“")

        // 6. è®¾ç½®è¾“å‡ºä¾§æ ¼å¼ï¼ˆAudioUnit è¾“å‡º = æˆ‘ä»¬çš„è¾“å…¥æ•°æ®ï¼‰
        var outputFormat = inputFormat // å…ˆä½¿ç”¨è¾“å…¥æ ¼å¼
        status = AudioUnitSetProperty(
            unit,
            kAudioUnitProperty_StreamFormat,
            kAudioUnitScope_Output,
            1, // è¾“å…¥æ€»çº¿çš„è¾“å‡ºä¾§
            &outputFormat,
            UInt32(MemoryLayout<AudioStreamBasicDescription>.size)
        )
        guard status == noErr else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to set output format: \(status)"])
        }

        // 7. è®¾ç½®è¾“å…¥å›è°ƒ
        var callbackStruct = AURenderCallbackStruct(
            inputProc: audioInputCallback,
            inputProcRefCon: Unmanaged.passUnretained(self).toOpaque()
        )
        status = AudioUnitSetProperty(
            unit,
            kAudioOutputUnitProperty_SetInputCallback,
            kAudioUnitScope_Global,
            0,
            &callbackStruct,
            UInt32(MemoryLayout<AURenderCallbackStruct>.size)
        )
        guard status == noErr else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to set callback: \(status)"])
        }

        // 8. è®¾ç½®æœ€å¤§å¸§æ•° (å…³é”®: å¿…é¡»åœ¨åˆå§‹åŒ–å‰è®¾ç½®)
        var maxFrames: UInt32 = 4096
        status = AudioUnitSetProperty(
            unit,
            kAudioUnitProperty_MaximumFramesPerSlice,
            kAudioUnitScope_Global,
            0,
            &maxFrames,
            UInt32(MemoryLayout<UInt32>.size)
        )
        guard status == noErr else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to set max frames: \(status)"])
        }

        // 9. åˆ›å»ºæ ¼å¼è½¬æ¢å™¨ï¼ˆä¿æŒä¸ AudioEngine ä¸€è‡´çš„é«˜è´¨é‡é‡é‡‡æ ·ï¼‰
        inputAVFormat = AVAudioFormat(streamDescription: &inputFormat)
        if let inputAVFormat {
            avAudioConverter = AVAudioConverter(from: inputAVFormat, to: targetAVFormat)
            avAudioConverter?.sampleRateConverterAlgorithm = AVSampleRateConverterAlgorithm_Mastering
        }

        // 10. åˆå§‹åŒ– Audio Unit
        status = AudioUnitInitialize(unit)
        guard status == noErr else {
            throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to initialize audio unit: \(status)"])
        }

        log.info("âœ… Audio Unit åˆå§‹åŒ–å®Œæˆ")
    }

    // MARK: - Audio Callback

    private let audioInputCallback: AURenderCallback = {
        inRefCon,
            ioActionFlags,
            inTimeStamp,
            inBusNumber,
            inNumberFrames,
            _
            -> OSStatus in
        let recorder = Unmanaged<AudioUnitRecorder>.fromOpaque(inRefCon).takeUnretainedValue()

        guard recorder.recordState == .recording else {
            return noErr
        }

        guard let inputFormat = recorder.inputAVFormat,
              let buffer = AVAudioPCMBuffer(
                  pcmFormat: inputFormat,
                  frameCapacity: AVAudioFrameCount(inNumberFrames)
              )
        else {
            return noErr
        }

        buffer.frameLength = AVAudioFrameCount(inNumberFrames)

        // è·å–éŸ³é¢‘æ•°æ®ï¼ˆç›´æ¥æ¸²æŸ“è¿› AVAudioPCMBufferï¼‰
        let status = AudioUnitRender(
            recorder.audioUnit!,
            ioActionFlags,
            inTimeStamp,
            inBusNumber,
            inNumberFrames,
            buffer.mutableAudioBufferList
        )

        guard status == noErr else {
            log.error("AudioUnitRender failed: \(status)")
            return status
        }

        // å¤„ç†éŸ³é¢‘æ•°æ®
        recorder.processAudioBuffer(buffer)

        return noErr
    }

    private func processAudioBuffer(_ inputBuffer: AVAudioPCMBuffer) {
        guard let converter = avAudioConverter else { return }

        // ä»¥ä¸ AudioEngine ç›¸åŒçš„è·¯å¾„é‡é‡‡æ ·
        let estimatedOutputFrames = AVAudioFrameCount(
            Double(inputBuffer.frameLength)
                * targetAVFormat.sampleRate
                / inputBuffer.format.sampleRate
        ) + 1

        guard let outputBuffer = AVAudioPCMBuffer(
            pcmFormat: targetAVFormat,
            frameCapacity: max(estimatedOutputFrames, 1)
        ) else { return }

        var error: NSError?
        let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            outStatus.pointee = .haveData
            return inputBuffer
        }

        guard status != .error else {
            log.error("Audio convert failed: \(error?.localizedDescription ?? "unknown")")
            return
        }

        guard let pcmData = pcmBufferToData(outputBuffer), !pcmData.isEmpty else { return }
        recordedAudioData.append(pcmData)

        let volume = calculateVolume(from: pcmData)
        EventBus.shared.publish(.volumeChanged(volume: volume))

        totalRawBytesSent += pcmData.count
        encodeAndQueue(pcmData)
    }

    private func encodeAndQueue(_ pcmData: Data) {
        // è½¬æ¢ä¸º AVAudioPCMBuffer ä¾› Opus ç¼–ç å™¨ä½¿ç”¨
        let frameCount = pcmData.count / Int(targetFormat.mBytesPerFrame)
        let avFormat = AVAudioFormat(
            commonFormat: .pcmFormatInt16,
            sampleRate: Double(targetFormat.mSampleRate),
            channels: AVAudioChannelCount(targetFormat.mChannelsPerFrame),
            interleaved: true
        )!

        guard let buffer = AVAudioPCMBuffer(pcmFormat: avFormat, frameCapacity: AVAudioFrameCount(frameCount)) else {
            return
        }

        buffer.frameLength = AVAudioFrameCount(frameCount)

        pcmData.withUnsafeBytes { rawBufferPointer in
            guard let baseAddress = rawBufferPointer.baseAddress else { return }
            let dest = buffer.audioBufferList.pointee.mBuffers.mData!
            memcpy(dest, baseAddress, pcmData.count)
        }

        // Opus ç¼–ç 
        for opusFrame in opusEncoder.encodeBuffer(buffer) {
            for packet in oggPacketizer.append(frame: opusFrame) {
                audioQueue.append(packet)
            }
        }

        handleQueuedAudio()
    }

    private func calculateVolume(from data: Data) -> Float {
        guard data.count >= 2 else { return 0.0 }

        let samples = data.withUnsafeBytes { $0.bindMemory(to: Int16.self) }
        var sum: Float = 0.0

        for sample in samples {
            let normalized = Float(sample) / Float(Int16.max)
            sum += normalized * normalized
        }

        let rms = sqrt(sum / Float(samples.count))
        return min(1.0, rms * 10.0)
    }

    // MARK: - å½•éŸ³æ§åˆ¶

    func currentRecordingDuration() -> TimeInterval {
        guard let startTime = recordingStartTime else {
            return 0
        }
        return Date().timeIntervalSince(startTime)
    }

    @MainActor
    func startRecording(mode: RecordMode = .normal) {
        guard recordState == .idle else {
            log.warning("Cant Start recording, now state: \(recordState)")
            return
        }

        // é‡ç½®å½•éŸ³çŠ¶æ€,ä½†ä¸æ¸…ç† Audio Unit
        resetRecordingState()
        recordState = .recording
        recordMode = mode

        do {
            // å»¶è¿Ÿåˆå§‹åŒ–: åªåœ¨é¦–æ¬¡æˆ–é‡å»ºååˆå§‹åŒ–
            try setupAudioUnit()

            guard let unit = audioUnit else {
                throw NSError(domain: "AudioUnit", code: -1, userInfo: [NSLocalizedDescriptionKey: "Audio unit not initialized"])
            }

            // å¯åŠ¨ Audio Unit (ä¸é‡æ–°åˆå§‹åŒ–)
            var status = AudioOutputUnitStart(unit)

            // å¦‚æœé”™è¯¯æ˜¯ -10867
            // å¯èƒ½æ˜¯ Audio Unit å·²åœ¨è¿è¡Œ,å…ˆåœæ­¢å†å¯åŠ¨
            if status == -10867 {
                log.warning("Audio Unit å¯èƒ½å·²åœ¨è¿è¡Œ,å°è¯•å…ˆåœæ­¢å†å¯åŠ¨")
                AudioOutputUnitStop(unit)
                status = AudioOutputUnitStart(unit)
            }

            guard status == noErr else {
                throw NSError(domain: "AudioUnit", code: Int(status), userInfo: [NSLocalizedDescriptionKey: "Failed to start audio unit: \(status)"])
            }

            startRecordingTimers()
            log.info("ğŸ™ï¸ å¼€å§‹å½•éŸ³")

        } catch {
            log.error("ğŸ™… Failed to start recording: \(error.localizedDescription)".red)
            recordState = .idle
        }
    }

    @MainActor
    func stopRecording(
        stopState: RecordState = .processing,
        shouldSetResponseTimer: Bool = true
    ) {
        guard recordState == .recording else {
            return
        }

        recordState = .stopping
        recordingStopTime = Date()

        // åœæ­¢ Audio Unit, ä¸é”€æ¯
        if let unit = audioUnit {
            AudioOutputUnitStop(unit)
        }

        // åˆ·æ–°ç¼–ç å™¨ç¼“å†²åŒº
        if let encoder = opusEncoder, let finalData = encoder.flush() {
            for packet in oggPacketizer.append(frame: finalData) {
                audioQueue.append(packet)
            }
        }

        flushPendingOggPackets(final: true)
        while let audioData = audioQueue.popFirst() {
            sendAudioData(audioData)
        }

        // å¤„ç†å“åº”
        let canRecord = ConnectionCenter.shared.canRecord()
        let hasNetworkError = ConnectionCenter.shared.hasRecordingNetworkError()

        if !canRecord || hasNetworkError, !ConnectionCenter.shared.canResumeAfterNetworkError(), isRecordingStarted {
            saveAudioToDatabase(error: "è½¬å½•æœªå®Œæˆï¼Œä½ å¯åœ¨æ­¤å¤„é‡æ–°è½¬å½•")
        }

        let shouldStopNormally = canRecord && (hasNetworkError || isRecordingStarted)

        recordState = shouldStopNormally ? stopState : .idle
        printRecordingStatistics()

        EventBus.shared.publish(
            .recordingStopped(
                isRecordingStarted: isRecordingStarted,
                shouldSetResponseTimer: shouldStopNormally && shouldSetResponseTimer
            )
        )
        log.info("âœ… å½•éŸ³åœæ­¢")
    }

    @MainActor
    func resetState() {
        recordState = .idle
        resetRecordingState()
    }

    // é‡ç½®å½•éŸ³çŠ¶æ€ä½†ä¿ç•™ Audio Unit
    private func resetRecordingState() {
        audioQueue.removeAll()
        recordedAudioData.removeAll()
        if let unit = audioUnit {
            AudioOutputUnitStop(unit)
        }

        totalPacketsSent = 0
        totalBytesSent = 0
        totalRawBytesSent = 0
        recordingStartTime = Date()
        recordingStopTime = nil
        isRecordingStarted = false
        queueStartTime = nil

        opusEncoder.reset()
        oggPacketizer.reset()
        stopRecordingTimers()
    }

    private func cleanup() {
        lock.lock()
        defer { lock.unlock() }

        if let unit = audioUnit {
            AudioOutputUnitStop(unit)
            AudioUnitUninitialize(unit)
            AudioComponentInstanceDispose(unit)
        }

        audioUnit = nil
        avAudioConverter = nil
        inputAVFormat = nil

        log.debug("Audio Unit Cleaned Up!")
    }

    // MARK: - è®¾å¤‡åˆ‡æ¢

    @MainActor
    private func reconfigureAudioUnit() async {
        let wasRecording = recordState == .recording

        if wasRecording {
            stopRecording(stopState: .idle, shouldSetResponseTimer: false)
        }

        // è®¾å¤‡åˆ‡æ¢æ—¶å¿…é¡»å®Œå…¨é‡å»º Audio Unit
        cleanup()

        // ç­‰å¾…è®¾å¤‡ç¨³å®šå’Œèµ„æºé‡Šæ”¾
        // è¿™ä¸ªå»¶è¿Ÿå¾ˆé‡è¦,ç¡®ä¿:
        // 1. æ—§è®¾å¤‡èµ„æºå®Œå…¨é‡Šæ”¾
        // 2. æ–°è®¾å¤‡å®Œå…¨æ¿€æ´»
        // 3. ç³»ç»ŸéŸ³é¢‘æœåŠ¡å™¨çŠ¶æ€ç¨³å®š
        try? await Task.sleep(nanoseconds: 500_000_000) // 500ms

        if wasRecording {
            startRecording(mode: recordMode)
        }

        log.info("âœ… Audio Unit å·²é‡æ–°é…ç½®".yellow)
    }

    private func flushPendingOggPackets(final: Bool) {
        guard let packetizer = oggPacketizer else { return }
        for packet in packetizer.flush(final: final) {
            audioQueue.append(packet)
        }
    }

    private func sendAudioData(_ audioData: Data) {
        totalPacketsSent += 1
        totalBytesSent += audioData.count
        EventBus.shared.publish(.audioDataReceived(data: audioData))
    }

    func handleModeUpgrade(from _: RecordMode, to: RecordMode) {
        if isRecordingStarted {
            EventBus.shared.publish(.modeUpgraded(from: .normal, to: to))
        } else if to != .normal {
            recordMode = to
        }
    }

    private func saveAudioToDatabase(content: String = "", error: String = "") {
        guard let dir = UserConfigService.shared.audiosDirectory, isRecordingStarted else { return }

        if let startTime = recordingStartTime, let stopTime = recordingStopTime {
            let duration = stopTime.timeIntervalSince(startTime)
            if duration < 0.5 {
                log.info("å½•éŸ³æ—¶é•¿å°äº 500 æ¯«ç§’ (\(Int(duration * 1000))ms), ä¸ä¿å­˜")
                return
            }
        }

        // å½“è®¾ç½®ä¸º "never" ä¸”æ²¡æœ‰é”™è¯¯æ—¶ï¼Œä¸ä¿å­˜
        if Config.shared.USER_CONFIG.setting.historyRetention == "never", error.isEmpty {
            return
        }

        let sessionID = ConnectionCenter.shared.currentRecordingAppContext.sessionID
        let filename = "\(sessionID).wav"
        let fileURL = dir.appendingPathComponent(filename)

        do {
            let wavData = toWavData(fromPCM: recordedAudioData, targetFormat: targetFormat)
            try wavData.write(to: fileURL)
            let clearBeforeInsert = Config.shared.USER_CONFIG.setting.historyRetention == "never" && !error.isEmpty
            try DatabaseService.shared.saveAudios(sessionID: sessionID, filename: filename, content: content, error: error, clearBeforeInsert: clearBeforeInsert)
            log.info("Audio saved to file: \(filename) \nError: \(error)\nContent: \(content)")
            EventBus.shared.publish(.userAudioSaved(sessionID: sessionID, filename: filename))
        } catch {
            log.error("Failed to save recording: \(error)")
        }
    }

    private func pcmBufferToData(_ buffer: AVAudioPCMBuffer) -> Data? {
        guard buffer.frameLength > 0 else { return nil }

        let bytesPerFrame = Int(buffer.format.streamDescription.pointee.mBytesPerFrame)
        let realDataCount = Int(buffer.frameLength) * bytesPerFrame

        guard let mData = buffer.audioBufferList.pointee.mBuffers.mData else { return nil }
        return Data(bytes: mData, count: realDataCount)
    }

    func getCurrentRecordingSessionDuration() -> TimeInterval {
        if let startTime = recordingStartTime, let stopTime = recordingStopTime {
            return stopTime.timeIntervalSince(startTime)
        }
        return 0
    }

    func getCurrentRecordingSessionMode() -> RecordMode {
        recordMode
    }
}

// MARK: - å“åº”å¼éŸ³é¢‘æµå¤„ç†

extension AudioUnitRecorder {
    private func setupAudioEventListener() {
        ConnectionCenter.shared.$wssState
            .combineLatest(ConnectionCenter.shared.$permissionsState)
            .sink { [weak self] _, _ in
                self?.handleConnectionStateChange()
            }
            .store(in: &cancellables)

        EventBus.shared.events
            .sink { [weak self] event in
                switch event {
                case let .serverResultReceived(summary, _, _, _):
                    Task { @MainActor in
                        if self?.recordState == .processing {
                            self?.saveAudioToDatabase(content: summary)
                            self?.resetState()
                        }
                    }
                case let .terminalLinuxChoice(_, _, _, commands):
                    Task { @MainActor in
                        if self?.recordState == .processing {
                            self?.saveAudioToDatabase(content: commands.map { $0.displayName }.joined(separator: "\n"))
                            self?.resetState()
                        }
                    }
                case let .notificationReceived(messageType):
                    switch messageType {
                    case .serverTimeout:
                        Task { @MainActor in
                            self?.saveAudioToDatabase(error: "è½¬å½•æœªå®Œæˆï¼Œä½ å¯åœ¨æ­¤å¤„é‡æ–°è½¬å½•")
                            self?.resetState()
                        }

                    case let .networkUnavailable(duringRecording):
                        Task { @MainActor in
                            // åœ¨å½•éŸ³è¿‡ç¨‹ä¸­æ–­ç½‘
                            // éœ€è¦ç»§ç»­ä¿å­˜å½•éŸ³
                            if duringRecording {
                            } else {
                                self?.resetState()
                            }
                        }

                    case .error:
                        Task { @MainActor in
                            self?.saveAudioToDatabase(error: "è½¬å½•æœªå®Œæˆï¼Œä½ å¯åœ¨æ­¤å¤„é‡æ–°è½¬å½•")
                            self?.resetState()
                        }

                    case .serverUnavailable(duringRecording: true):
                        log.error("Server unavailable, stop recording")
                        Task { @MainActor in
                            if self?.recordState == .processing {
                                self?.saveAudioToDatabase(error: "è½¬å½•æœªå®Œæˆï¼Œä½ å¯åœ¨æ­¤å¤„é‡æ–°è½¬å½•")
                                self?.resetState()
                            } else {
                                self?.stopRecording(stopState: .idle, shouldSetResponseTimer: false)
                            }
                        }

                    default:
                        break
                    }
                case .audioDeviceChanged:
                    Task { @MainActor in
                        await self?.reconfigureAudioUnit()
                    }
                default:
                    break
                }
            }
            .store(in: &cancellables)
    }

    private func handleQueuedAudio() {
        guard recordState == .recording else { return }
        guard ConnectionCenter.shared.canRecord() else {
            checkAndHandleTimeout()
            return
        }

        processAudioQueue()
    }

    private func handleConnectionStateChange() {
        guard recordState == .recording, ConnectionCenter.shared.canRecord(), !isRecordingStarted else {
            return
        }

        queueStartTime = nil
        processAudioQueue()
    }

    private func processAudioQueue() {
        startRecordingIfNeeded()
        flushAudioQueue()
    }

    private func flushAudioQueue() {
        guard !audioQueue.isEmpty else { return }
        while let audioData = audioQueue.popFirst() {
            sendAudioData(audioData)
        }
    }

    private func startRecordingIfNeeded() {
        guard !isRecordingStarted else { return }

        isRecordingStarted = true
        EventBus.shared.publish(.recordingStarted(mode: recordMode))
    }

    private func checkAndHandleTimeout() {
        guard !isRecordingStarted else { return }

        if queueStartTime == nil {
            queueStartTime = Date()
            log.warning("Set queue start time")
            EventBus.shared.publish(.recordingCacheStarted(mode: recordMode))
        } else if let startTime = queueStartTime, Date().timeIntervalSince(startTime) >= 3.0 {
            log.error("Audio queue timeout: failed to establish connection within 3 seconds.")
            Task { @MainActor in
                self.stopRecording()
                EventBus.shared.publish(.recordingCacheTimeout)
                EventBus.shared.publish(.notificationReceived(.networkUnavailable(duringRecording: false)))
            }
        }
    }
}

// MARK: - å®šæ—¶å™¨

extension AudioUnitRecorder {
    private func startRecordingTimers() {
        let warningTime = maxRecordingDuration - warningBeforeTimeout

        Task { @MainActor [weak self] in
            guard let self else { return }
            recordingLimitTimer = Timer.scheduledTimer(withTimeInterval: warningTime, repeats: false) { [weak self] _ in
                guard let self, recordState == .recording else { return }
                EventBus.shared.publish(.notificationReceived(.recordingTimeoutWarning))

                recordingLimitTimer = Timer.scheduledTimer(withTimeInterval: warningBeforeTimeout, repeats: false) { [weak self] _ in
                    guard let self, recordState == .recording else { return }
                    log.warning("Recording timeout: exceeded \(maxRecordingDuration) seconds")
                    Task { @MainActor in
                        EventBus.shared.publish(.recordingConfirmed)
                    }
                }
            }
        }
    }

    private func stopRecordingTimers() {
        recordingLimitTimer?.invalidate()
        recordingLimitTimer = nil
    }
}

// MARK: - ç»Ÿè®¡

extension AudioUnitRecorder {
    private func printRecordingStatistics() {
        guard let startTime = recordingStartTime,
              let stopTime = recordingStopTime,
              isRecordingStarted else { return }

        let duration = stopTime.timeIntervalSince(startTime)
        guard duration > 0 else { return }

        let avgPacketSize = totalPacketsSent > 0 ? Double(totalBytesSent) / Double(totalPacketsSent) : 0
        let packetsPerSecond = Double(totalPacketsSent) / duration
        let bytesPerSecond = Double(totalBytesSent) / duration

        let theoreticalBytes = Int(duration * 16000 * 2)

        let compressionRatio = totalRawBytesSent > 0 ? Double(totalRawBytesSent) / Double(totalBytesSent) : 1.0
        let compressionPercentage = totalRawBytesSent > 0 ? (1.0 - Double(totalBytesSent) / Double(totalRawBytesSent)) * 100.0 : 0.0
        let bandwidthSaved = totalRawBytesSent - totalBytesSent

        log.info(
            """
            ğŸ“Š å½•éŸ³ç»Ÿè®¡æŠ¥å‘Š (Audio Unit):
               ğŸ“¦ æ€»åŒ…æ•°ç›®: \(totalPacketsSent) ä¸ª
               ğŸ¤¡ å½•éŸ³æ—¶é•¿: \(String(format: "%.2f", duration)) ç§’

               ğŸ’¾ åŸå§‹æ•°æ®: \(formatBytes(totalRawBytesSent))
               ğŸ“¦ å‹ç¼©æ•°æ®: \(formatBytes(totalBytesSent))
               ğŸ¤¡ å‹ç¼©æ¯”ä¾‹: \(String(format: "%.1f", compressionRatio)):1
               ğŸ’° å‹ç¼©ç‡: \(String(format: "%.1f", compressionPercentage))%
               ğŸ¤¡ èŠ‚çœå¸¦å®½: \(formatBytes(bandwidthSaved))

               ğŸ“Š å¹³å‡åŒ…å¤§å°: \(String(format: "%.1f", avgPacketSize)) å­—èŠ‚
               ğŸ“ˆ å‘é€é¢‘ç‡: \(String(format: "%.1f", packetsPerSecond)) åŒ…/ç§’
               ğŸ“ˆ æ•°æ®é€Ÿç‡: \(String(format: "%.1f", bytesPerSecond / 1024.0)) KB/ç§’
               ğŸ¯ ç†è®ºæ•°æ®: \(formatBytes(theoreticalBytes)) (\(String(format: "%.1f", Double(totalRawBytesSent) / Double(theoreticalBytes) * 100.0))%)
            """)
    }

    private func formatBytes(_ bytes: Int) -> String {
        let kb = Double(bytes) / 1024.0
        return String(format: "%.2f KB (%d å­—èŠ‚)", kb, bytes)
    }
}
