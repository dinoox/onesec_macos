//
//  OCR.swift
//  OnesecCore
//
//  Created by AI Assistant on 2025/10/27.
//

import Cocoa
import CoreGraphics
@preconcurrency import Vision

// MARK: - è¯†åˆ«ç»“æžœ

struct RecognizedText {
    let text: String
    let boundingBox: CGRect // å½’ä¸€åŒ–åæ ‡ (0.0-1.0)
}

// MARK: - OCRæœåŠ¡

class OCRService {
    /// æˆªå–å‰å°çª—å£å¹¶è¯†åˆ«æ–‡å­—
    static func captureFrontWindowAndRecognize() async -> [RecognizedText] {
        guard let windowImage = captureFrontWindow() else {
            log.error("æ— æ³•æˆªå–å‰å°çª—å£")
            return []
        }

        return await recognizeText(from: windowImage)
    }

    /// èŽ·å–å‰å°çª—å£çš„çº¯æ–‡æœ¬å†…å®¹
    static func captureFrontWindowText() async -> String {
        let results = await captureFrontWindowAndRecognize()
        return results.map(\.text).joined(separator: "\n")
    }

    /// èŽ·å–å‰å°çª—å£çš„æˆªå›¾
    static func captureFrontWindow() -> CGImage? {
        let permissionService = PermissionService.shared
        let screenStatus = permissionService.checkStatus(.screenRecording)
        if screenStatus != .granted {
            Task { @MainActor in
                OverlayController.shared.showOverlay { panelId in
                    NotificationCard(
                        title: "æœªèŽ·å¾—å±å¹•å½•åˆ¶æƒé™",
                        content: "è¯·åœ¨ç³»ç»Ÿåå¥½è®¾ç½®ä¸­å…è®¸å±å¹•å½•åˆ¶æƒé™",
                        panelId: panelId,
                        modeColor: starlightYellow,
                        autoHide: true,
                        onTap: {
                            PermissionService.shared.request(.screenRecording) { _ in }
                        },
                        onClose: nil
                    )
                }
            }
            EventBus.shared.publish(.serverResultReceived(summary: "", interactionID: "", processMode: .auto, polishedText: ""))
            return nil
        }

        guard let winList = CGWindowListCopyWindowInfo([.optionOnScreenOnly, .excludeDesktopElements], kCGNullWindowID) as? [[String: Any]],
              let frontApp = NSWorkspace.shared.frontmostApplication
        else {
            return nil
        }

        let frontPID = frontApp.processIdentifier
        let frontAppName = frontApp.localizedName ?? "Unknown"

        // æŸ¥æ‰¾å‰å°åº”ç”¨çš„ä¸»çª—å£ï¼ˆLayer = 0ï¼‰
        for window in winList {
            guard let pid = window[kCGWindowOwnerPID as String] as? Int32,
                  pid == frontPID,
                  let layer = window[kCGWindowLayer as String] as? Int,
                  layer == 0,
                  let bounds = window[kCGWindowBounds as String] as? [String: CGFloat],
                  let x = bounds["X"], let y = bounds["Y"],
                  let width = bounds["Width"], let height = bounds["Height"],
                  width > 100, height > 100
            else {
                continue
            }

            let rect = CGRect(x: x, y: y, width: width, height: height)

            guard let image = CGDisplayCreateImage(CGMainDisplayID(), rect: rect) else {
                continue
            }

            log.info("ðŸ“¸ Screen capture: \(frontAppName) (\(Int(width))Ã—\(Int(height)))")
            saveImageToFile(image, appName: frontAppName)
            return image
        }

        // å›žé€€åˆ°å…¨å±æˆªå›¾
        guard let fullScreenImage = CGDisplayCreateImage(CGMainDisplayID()) else {
            log.error("Screen capture failed, please check the screen recording permission")
            return nil
        }

        saveImageToFile(fullScreenImage, appName: "FullScreen")
        return fullScreenImage
    }

    /// ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°
    private static func saveImageToFile(_ cgImage: CGImage, appName: String) {
        // åˆ›å»ºä¿å­˜ç›®å½•
        let documentsPath = FileManager.default.urls(for: .downloadsDirectory, in: .userDomainMask)[0]
        let screenshotsFolder = documentsPath.appendingPathComponent("OnesecScreenshots")

        // ç¡®ä¿ç›®å½•å­˜åœ¨
        try? FileManager.default.createDirectory(at: screenshotsFolder, withIntermediateDirectories: true)

        // ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨æ—¶é—´æˆ³å’Œåº”ç”¨åï¼‰
        let dateFormatter = DateFormatter()
        dateFormatter.dateFormat = "yyyy-MM-dd_HH-mm-ss"
        let timestamp = dateFormatter.string(from: Date())
        let sanitizedAppName = appName.replacingOccurrences(of: " ", with: "_")
        let fileName = "screenshot_\(sanitizedAppName)_\(timestamp).png"
        let fileURL = screenshotsFolder.appendingPathComponent(fileName)

        // å°† CGImage è½¬æ¢ä¸º NSBitmapImageRep å¹¶ä¿å­˜ä¸º PNG
        let bitmapRep = NSBitmapImageRep(cgImage: cgImage)
        guard let pngData = bitmapRep.representation(using: .png, properties: [:]) else {
            log.error("æ— æ³•å°†å›¾ç‰‡è½¬æ¢ä¸ºPNGæ ¼å¼")
            return
        }

        do {
            try pngData.write(to: fileURL)
            log.info("âœ… æˆªå›¾å·²ä¿å­˜åˆ°: \(fileURL.path)")
        } catch {
            log.error("ä¿å­˜æˆªå›¾å¤±è´¥: \(error.localizedDescription)")
        }
    }

    /// ä»Žå›¾åƒè¯†åˆ«æ–‡å­—
    private static func recognizeText(from image: CGImage) async -> [RecognizedText] {
        await withCheckedContinuation { continuation in
            let request = VNRecognizeTextRequest { request, error in
                if let error {
                    log.error("RecognizeText failed: \(error.localizedDescription)")
                    continuation.resume(returning: [])
                    return
                }

                guard let observations = request.results as? [VNRecognizedTextObservation] else {
                    continuation.resume(returning: [])
                    return
                }

                let results = observations.compactMap { observation -> RecognizedText? in
                    guard let candidate = observation.topCandidates(1).first else {
                        return nil
                    }
                    return RecognizedText(text: candidate.string, boundingBox: observation.boundingBox)
                }

                log.info("Recognize \(results.count) texts")
                continuation.resume(returning: results)
            }

            // é…ç½®è¯†åˆ«å‚æ•°
            request.recognitionLevel = .accurate
            request.usesLanguageCorrection = true
            request.recognitionLanguages = ["zh-Hans", "zh-Hant", "en-US"]

            // æ‰§è¡Œè¯†åˆ«
            let handler = VNImageRequestHandler(cgImage: image, options: [:])
            DispatchQueue.global(qos: .userInitiated).async {
                do {
                    try handler.perform([request])
                } catch {
                    log.error("OCRè¯·æ±‚æ‰§è¡Œå¤±è´¥: \(error.localizedDescription)")
                    continuation.resume(returning: [])
                }
            }
        }
    }
}

private extension DateFormatter {
    func apply(_ closure: (DateFormatter) -> Void) -> DateFormatter {
        closure(self)
        return self
    }
}
